{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Thakker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "data1 = np.genfromtxt('xf.csv', delimiter=',')\n",
    "data2 = np.genfromtxt('yf.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (624, 784) (624,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(data1,data2, test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  26\n",
      "Output classes :  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25.]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(train_Y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((624, 28, 28, 1), (156, 28, 28, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X.reshape(-1, 28,28, 1)\n",
    "test_X = test_X.reshape(-1, 28,28, 1)\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 7.0\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[1])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((499, 28, 28, 1), (125, 28, 28, 1), (499, 26), (125, 26))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "num_classes = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.4))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))           \n",
    "fashion_model.add(Dropout(0.3))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 358,298\n",
      "Trainable params: 358,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 499 samples, validate on 125 samples\n",
      "Epoch 1/50\n",
      "499/499 [==============================] - 1s 3ms/step - loss: 3.2666 - accuracy: 0.0441 - val_loss: 3.2262 - val_accuracy: 0.0560\n",
      "Epoch 2/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 3.1587 - accuracy: 0.1042 - val_loss: 3.1396 - val_accuracy: 0.1280\n",
      "Epoch 3/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 2.9572 - accuracy: 0.1864 - val_loss: 2.7943 - val_accuracy: 0.2080\n",
      "Epoch 4/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 2.5669 - accuracy: 0.2425 - val_loss: 2.2585 - val_accuracy: 0.4320\n",
      "Epoch 5/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 2.1778 - accuracy: 0.3707 - val_loss: 2.0746 - val_accuracy: 0.3760\n",
      "Epoch 6/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 1.8118 - accuracy: 0.4349 - val_loss: 1.6464 - val_accuracy: 0.5120\n",
      "Epoch 7/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 1.5737 - accuracy: 0.5070 - val_loss: 1.4868 - val_accuracy: 0.6000\n",
      "Epoch 8/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 1.4330 - accuracy: 0.5471 - val_loss: 1.3006 - val_accuracy: 0.6480\n",
      "Epoch 9/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 1.1347 - accuracy: 0.6493 - val_loss: 1.1711 - val_accuracy: 0.6640\n",
      "Epoch 10/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 1.1101 - accuracy: 0.6393 - val_loss: 1.0419 - val_accuracy: 0.7120\n",
      "Epoch 11/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.9137 - accuracy: 0.6894 - val_loss: 0.9427 - val_accuracy: 0.7280\n",
      "Epoch 12/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.7998 - accuracy: 0.7475 - val_loss: 0.8003 - val_accuracy: 0.7760\n",
      "Epoch 13/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.7715 - val_loss: 0.7946 - val_accuracy: 0.7600\n",
      "Epoch 14/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.6580 - accuracy: 0.7675 - val_loss: 0.7271 - val_accuracy: 0.7840\n",
      "Epoch 15/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.8096 - val_loss: 0.6901 - val_accuracy: 0.8000\n",
      "Epoch 16/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.8637 - val_loss: 0.6204 - val_accuracy: 0.8560\n",
      "Epoch 17/50\n",

      "499/499 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8677 - val_loss: 0.6053 - val_accuracy: 0.8080\n",
      "Epoch 18/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.4037 - accuracy: 0.8737 - val_loss: 0.5395 - val_accuracy: 0.8560\n",
      "Epoch 19/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8858 - val_loss: 0.5042 - val_accuracy: 0.8720\n",
      "Epoch 20/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.3096 - accuracy: 0.8898 - val_loss: 0.4825 - val_accuracy: 0.8800\n",
      "Epoch 21/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.9238 - val_loss: 0.5279 - val_accuracy: 0.8720\n",
      "Epoch 22/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.9279 - val_loss: 0.4906 - val_accuracy: 0.8560\n",
      "Epoch 23/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.2024 - accuracy: 0.9359 - val_loss: 0.4846 - val_accuracy: 0.8720\n",
      "Epoch 24/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.2038 - accuracy: 0.9419 - val_loss: 0.4332 - val_accuracy: 0.8960\n",
      "Epoch 25/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9259 - val_loss: 0.4750 - val_accuracy: 0.8880\n",
      "Epoch 26/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9319 - val_loss: 0.4848 - val_accuracy: 0.8800\n",
      "Epoch 27/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9459 - val_loss: 0.5004 - val_accuracy: 0.8720\n",
      "Epoch 28/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.9499 - val_loss: 0.4293 - val_accuracy: 0.9120\n",
      "Epoch 29/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1697 - accuracy: 0.9439 - val_loss: 0.4306 - val_accuracy: 0.8720\n",
      "Epoch 30/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1528 - accuracy: 0.9439 - val_loss: 0.4261 - val_accuracy: 0.8880\n",
      "Epoch 31/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9699 - val_loss: 0.3986 - val_accuracy: 0.8720\n",
      "Epoch 32/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1113 - accuracy: 0.9579 - val_loss: 0.4150 - val_accuracy: 0.8560\n",
      "Epoch 33/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1175 - accuracy: 0.9639 - val_loss: 0.5391 - val_accuracy: 0.8720\n",
      "Epoch 34/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1337 - accuracy: 0.9519 - val_loss: 0.5098 - val_accuracy: 0.8720\n",
      "Epoch 35/50\n",
      "499/499 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9619 - val_loss: 0.4259 - val_accuracy: 0.9040\n",
      "Epoch 36/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9739 - val_loss: 0.4369 - val_accuracy: 0.9120\n",
      "Epoch 37/50\n",
      "499/499 [==============================] - 1s 3ms/step - loss: 0.1129 - accuracy: 0.9459 - val_loss: 0.5242 - val_accuracy: 0.8560\n",
      "Epoch 38/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9719 - val_loss: 0.4469 - val_accuracy: 0.9040\n",
      "Epoch 39/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9760 - val_loss: 0.3621 - val_accuracy: 0.8960\n",
      "Epoch 40/50\n",
      "499/499 [==============================] - 1s 3ms/step - loss: 0.1103 - accuracy: 0.9639 - val_loss: 0.4642 - val_accuracy: 0.8640\n",
      "Epoch 41/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9780 - val_loss: 0.4627 - val_accuracy: 0.8800\n",
      "Epoch 42/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0713 - accuracy: 0.9719 - val_loss: 0.4475 - val_accuracy: 0.8880\n",
      "Epoch 43/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9739 - val_loss: 0.4485 - val_accuracy: 0.8960\n",
      "Epoch 44/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9719 - val_loss: 0.4648 - val_accuracy: 0.8880\n",
      "Epoch 45/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9659 - val_loss: 0.4295 - val_accuracy: 0.8880\n",
      "Epoch 46/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9820 - val_loss: 0.4088 - val_accuracy: 0.8720\n",
      "Epoch 47/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.9760 - val_loss: 0.4508 - val_accuracy: 0.8720\n",
      "Epoch 48/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.9760 - val_loss: 0.3929 - val_accuracy: 0.9040\n",
      "Epoch 49/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.4161 - val_accuracy: 0.8880\n",
      "Epoch 50/50\n",
      "499/499 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9760 - val_loss: 0.3626 - val_accuracy: 0.9280\n"
     ]
    }
   ],
   "source": [
    "fashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fashion_model.save(\"fashion_model_dropout.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4158020187646915\n",
      "Test accuracy: 0.8974359035491943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character found is I\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "\n",
    "img = imread('g.png')\n",
    "img = img[:,:,0]\n",
    "\n",
    "a = np.array(img)\n",
    "\n",
    "b = a.ravel()\n",
    "\n",
    "\n",
    "\n",
    "b=b.reshape(1,28,28,1)\n",
    "predicted_classes=fashion_model.predict(b)\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "\n",
    "print(\"Character found is \"+chr(int(predicted_classes+65)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
